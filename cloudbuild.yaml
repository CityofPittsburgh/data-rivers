steps:
- name: 'gcr.io/data-rivers/airflow'
  volumes:
    - name: 'vol1'
      path: '/persistent_volume'
  id: 'install_dataflow_utils'
  entrypoint: python
  args:
    - '/workspace/dags/dependencies/dataflow_scripts/setup.py'
    - 'install'
- name: 'gcr.io/data-rivers/airflow'
  volumes:
    - name: 'vol1'
      path: '/persistent_volume'
  id: 'install_requirements'
  waitFor:
    - 'install_dataflow_utils'
  entrypoint: /bin/sh
  args:
    - -c
    - 'pip install -r requirements.txt && pip install -r requirements-gcp.txt'
- name: 'gcr.io/data-rivers/airflow'
  volumes:
    - name: 'vol1'
      path: '/persistent_volume'
  id: 'tests'
  waitFor:
    - 'install_requirements'
  entrypoint: /bin/sh
  args:
    - 'pytest'
  env:
    - 'GCLOUD_PROJECT=data-rivers'
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
  id: 'deploy_if_master'
  waitFor:
    - 'tests'
  entrypoint: bash
  args:
    - -c
    - 'if [ "$BRANCH_NAME" == "master" ]; then echo "$BRANCH_NAME" && make deploy;
        else echo "Working on $BRANCH_NAME"; fi'